{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0RboudMm2bGNO7WFs3rkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edenshmuel/ICU_Nutrition_ML/blob/main/Pipeline_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook defines the preprocessing pipeline for both clustering and prediction models.\n",
        "It includes transformations for numerical, categorical, and skewed features**"
      ],
      "metadata": {
        "id": "tlrGG3q-Mw8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "zwky4Y8NMfk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
      ],
      "metadata": {
        "id": "KM2K6RqGJhZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log Transform + Scaling for skewed features"
      ],
      "metadata": {
        "id": "pEPQEqtXJS2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxbw2hxHI9yX"
      },
      "outputs": [],
      "source": [
        "log_scaler_pipeline = Pipeline(steps=[(\"log_transform\", FunctionTransformer(np.log1p, validate=True)),\n",
        "    (\"scaler\", MinMaxScaler())])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard Scaling for non-skewed features"
      ],
      "metadata": {
        "id": "1FIOmR_sJa2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_pipeline = Pipeline(steps=[(\"scaler\", MinMaxScaler())])"
      ],
      "metadata": {
        "id": "HFJrHPTBJV7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding for categorical features"
      ],
      "metadata": {
        "id": "mz0H0btiJxt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])"
      ],
      "metadata": {
        "id": "CridlTu3JaSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function converts the \"Disease\" column, which contains multiple diseases as a comma-separated string, into a multi-hot encoded format—creating a separate binary column for each unique disease"
      ],
      "metadata": {
        "id": "b9ee6DAHJ3Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def multi_hot_encode_disease(df):\n",
        "#     df = df.copy()\n",
        "#     df[\"Disease\"] = df[\"Disease\"].astype(str).str.split(\", \")\n",
        "#     all_diseases = set([d for sublist in df[\"Disease\"] for d in sublist])\n",
        "\n",
        "#     for disease in all_diseases:\n",
        "#         df[disease] = df[\"Disease\"].apply(lambda x: 1 if disease in x else 0)\n",
        "\n",
        "#     df = df.drop(columns=[\"Disease\"])\n",
        "#     return df\n",
        "\n",
        "# disease_transformer = FunctionTransformer(multi_hot_encode_disease)"
      ],
      "metadata": {
        "id": "UhDGu3sPJxJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# במקום FunctionTransformer למחלות, נשתמש בטרנספורמר מותאם אישית:\n",
        "class MultiHotDiseaseEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # אוספים את כל סוגי המחלות שקיימות בעמודה \"Disease\"\n",
        "        self.all_diseases_ = set()\n",
        "        for diseases_list in X[\"Disease\"].astype(str).str.split(\", \"):\n",
        "            self.all_diseases_.update(diseases_list)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        # הופכים כל ערך בעמודה Disease לרשימת מחלות\n",
        "        X[\"Disease\"] = X[\"Disease\"].astype(str).str.split(\", \")\n",
        "\n",
        "        # יוצרים עמודה בינארית לכל מחלה\n",
        "        for disease in self.all_diseases_:\n",
        "            X[disease] = X[\"Disease\"].apply(lambda lst: 1 if disease in lst else 0)\n",
        "\n",
        "        # מוחקים את עמודת Disease המקורית\n",
        "        X.drop(columns=[\"Disease\"], inplace=True)\n",
        "        return X\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        \"\"\"\n",
        "        מחזיר את שמות העמודות לאחר הקידוד הרב-ערכי.\n",
        "        input_features הוא רשימת העמודות המקורית (כולל \"Disease\").\n",
        "        \"\"\"\n",
        "        if input_features is None:\n",
        "            input_features = []\n",
        "        output_features = list(input_features)\n",
        "        # מסירים את \"Disease\" אם הוא קיים\n",
        "        if \"Disease\" in output_features:\n",
        "            output_features.remove(\"Disease\")\n",
        "        # מוסיפים את שמות העמודות החדשות (כל המחלות)\n",
        "        output_features.extend(sorted(self.all_diseases_))\n",
        "        return np.array(output_features, dtype=object)\n",
        "\n",
        "disease_transformer = MultiHotDiseaseEncoder()"
      ],
      "metadata": {
        "id": "ssuWOpZo8KeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code transforms the categorical \"Activity Level\" column into numerical values, making it suitable for machine learning models"
      ],
      "metadata": {
        "id": "-qZ8hdfrJ9bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activity_mapping = {\n",
        "    \"Sedentary\": 0,\n",
        "    \"Lightly Active\": 1,\n",
        "    \"Moderately Active\": 2,\n",
        "    \"Very Active\": 3,\n",
        "    \"Extremely Active\": 4\n",
        "    }"
      ],
      "metadata": {
        "id": "md4_CXUhJ6Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_activity_level(X):\n",
        "    X = X.copy()\n",
        "    X[\"Activity Level\"] = X[\"Activity Level\"].map(activity_mapping)\n",
        "    return X\n",
        "\n",
        "activity_transformer = FunctionTransformer(encode_activity_level)"
      ],
      "metadata": {
        "id": "jWO1NIblKDNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class is a custom scikit-learn transformer that calculates the Body Mass Index (BMI) based on weight and height"
      ],
      "metadata": {
        "id": "-A371_gvKIYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BMICalculator(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"BMI\"] = X[\"Weight\"] / (X[\"Height\"] ** 2)\n",
        "        return X"
      ],
      "metadata": {
        "id": "tAKarD-hKGR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "81aYHNAVKWe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_pipeline = Pipeline(steps=[\n",
        "    (\"bmi_calculator\", BMICalculator()),\n",
        "    (\"log_scaled\", log_scaler_pipeline),\n",
        "    (\"scaler\", scaler_pipeline)])"
      ],
      "metadata": {
        "id": "MxoSVCHBKKhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessor(numerical_features, categorical_features, Multy_categorical_features, right_skewed_features=None):\n",
        "    transformers = []\n",
        "\n",
        "    if right_skewed_features:\n",
        "        transformers.append((\"log_scaled\", log_scaler_pipeline, right_skewed_features))\n",
        "\n",
        "    transformers.append((\"activity\", activity_transformer, ordinal_features))\n",
        "\n",
        "    transformers.extend([\n",
        "        (\"num_pipeline\", num_pipeline, numerical_features),\n",
        "        (\"cat\", cat_transformer, categorical_features),\n",
        "        (\"disease\", disease_transformer, [\"Disease\"])])\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=transformers)\n",
        "\n",
        "    return preprocessor"
      ],
      "metadata": {
        "id": "2Q3YjGxKKZiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_names(preprocessor, input_features):\n",
        "    feature_names = []\n",
        "\n",
        "    for name, transformer, columns in preprocessor.transformers_:\n",
        "        if transformer == \"passthrough\":\n",
        "            if isinstance(columns[0], int):\n",
        "                feature_names.extend([input_features[i] for i in columns])\n",
        "            else:\n",
        "                feature_names.extend(columns)\n",
        "\n",
        "        elif isinstance(transformer, OneHotEncoder):\n",
        "            ohe_feature_names = transformer.get_feature_names_out(columns)\n",
        "            feature_names.extend(ohe_feature_names)\n",
        "\n",
        "        elif isinstance(transformer, Pipeline):\n",
        "            last_step = transformer.steps[-1][1]\n",
        "            if hasattr(last_step, \"get_feature_names_out\"):\n",
        "                try:\n",
        "                    fn = last_step.get_feature_names_out(columns)\n",
        "                    feature_names.extend(fn)\n",
        "                except:\n",
        "                    feature_names.extend(columns)\n",
        "            else:\n",
        "                feature_names.extend(columns)\n",
        "\n",
        "        elif hasattr(transformer, \"get_feature_names_out\"):\n",
        "            try:\n",
        "                fn = transformer.get_feature_names_out(columns)\n",
        "                feature_names.extend(fn)\n",
        "            except:\n",
        "                feature_names.extend(columns)\n",
        "        else:\n",
        "            feature_names.extend(columns)\n",
        "\n",
        "    # ✅ **נוסיף את \"BMI\" במקום המתאים**\n",
        "    if \"BMI\" not in feature_names:\n",
        "        index = feature_names.index(\"Weight\")  # BMI נוצר אחרי Weight\n",
        "        feature_names.insert(index + 1, \"BMI\")  # להכניס אותו מיד אחרי Weight\n",
        "\n",
        "    return feature_names\n"
      ],
      "metadata": {
        "id": "ltG5gBmaFW7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}